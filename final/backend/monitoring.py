"""
Production-Grade Performance Monitoring System

Features:
- Continuous metric sampling (100ms intervals)
- Per-request comprehensive tracking
- CSV export for analysis
- Cross-platform comparison support
- Dynamic hardware detection
"""

import json
import time
import asyncio
from datetime import datetime
from pathlib import Path
from dataclasses import asdict, dataclass, field
from typing import List, Dict, Any, Optional
import psutil
import torch
from loguru import logger
import csv


@dataclass
class MetricSnapshot:
    """Single point-in-time measurement"""
    timestamp: float
    cpu_percent: float
    memory_mb: float
    memory_percent: float
    gpu_memory_mb: float = 0.0
    gpu_percent: float = 0.0
    temperature_c: float = 0.0
    
    def to_dict(self) -> dict:
        return asdict(self)


@dataclass
class SynthesisMetrics:
    """Comprehensive metrics for a single synthesis request"""
    request_id: str
    hardware_tier: str
    device_type: str
    cpu_model: str
    cpu_cores: int
    total_memory_gb: float
    gpu_name: str = ""
    
    # Input
    text_length_chars: int = 0
    text_length_tokens: int = 0
    reference_audio_seconds: float = 0.0
    
    # Execution timing
    start_time: float = 0.0
    end_time: float = 0.0
    total_duration_s: float = 0.0
    
    # Memory profile
    peak_memory_mb: float = 0.0
    peak_memory_percent: float = 0.0
    
    # GPU metrics (if available)
    peak_gpu_memory_mb: float = 0.0
    
    # Thermal metrics
    peak_temperature_c: float = 0.0
    throttle_detected: bool = False
    
    # Performance
    rtf: float = 0.0  # Real-Time Factor
    tokens_per_second: float = 0.0
    audio_duration_s: float = 0.0  # Actual generated audio duration
    generated_tokens: int = 0  # Actual tokens generated by Fish Speech
    peak_gpu_util_pct: float = 0.0  # Peak GPU utilization percentage
    
    # Fish Speech specific metrics
    fish_tokens_per_sec: float = 0.0  # Fish Speech reported tokens/sec
    fish_bandwidth_gb_s: float = 0.0  # Fish Speech bandwidth (GB/s)
    fish_gpu_memory_gb: float = 0.0  # Fish Speech GPU memory used (GB)
    fish_generation_time_s: float = 0.0  # Fish Speech generation time (seconds)
    vq_features_shape: str = ""  # VQ features tensor shape
    
    # Quality metrics
    success: bool = True
    error_message: str = ""
    
    # Model state
    quantization_used: str = ""
    torch_compile_used: bool = False
    onnx_used: bool = False
    chunk_length: int = 0
    num_threads: int = 0
    
    def finalize(self, memory_snapshots: List[MetricSnapshot], gpu_snapshots: List[MetricSnapshot]):
        """Calculate derived metrics"""
        if len(memory_snapshots) > 0:
            self.peak_memory_mb = max(s.memory_mb for s in memory_snapshots)
            self.peak_memory_percent = max(s.memory_percent for s in memory_snapshots)
        
        if len(gpu_snapshots) > 0:
            self.peak_gpu_memory_mb = max(s.gpu_memory_mb for s in gpu_snapshots)
            self.peak_temperature_c = max(s.temperature_c for s in gpu_snapshots)
            # Get peak GPU utilization from snapshots if not already set
            if self.peak_gpu_util_pct == 0.0:
                gpu_utils = [s.gpu_percent for s in gpu_snapshots if s.gpu_percent > 0]
                if gpu_utils:
                    self.peak_gpu_util_pct = max(gpu_utils)
        
        # Calculate tokens/sec from actual generated tokens (if available)
        if self.total_duration_s > 0:
            if self.generated_tokens > 0:
                # Use actual generated tokens from Fish Speech
                self.tokens_per_second = self.generated_tokens / self.total_duration_s
            elif self.text_length_tokens > 0:
                # Fallback to input token estimate
                self.tokens_per_second = self.text_length_tokens / self.total_duration_s
            
            # Calculate RTF from actual audio duration (if available)
            if self.audio_duration_s > 0:
                # Use actual audio duration
                self.rtf = self.total_duration_s / self.audio_duration_s
            elif self.generated_tokens > 0:
                # Estimate from generated tokens: ~100 tokens = 2 seconds of audio
                estimated_audio_duration_s = (self.generated_tokens / 100) * 2
                self.rtf = self.total_duration_s / estimated_audio_duration_s if estimated_audio_duration_s > 0 else 0
            elif self.text_length_tokens > 0:
                # Fallback: estimate from input tokens
                estimated_audio_duration_s = (self.text_length_tokens / 100) * 2
                self.rtf = self.total_duration_s / estimated_audio_duration_s if estimated_audio_duration_s > 0 else 0


class PerformanceMonitor:
    """Comprehensive system performance monitoring"""
    
    def __init__(self, hardware_profile, output_dir: str = "./metrics"):
        self.profile = hardware_profile
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.current_synthesis: Optional[SynthesisMetrics] = None
        self.current_memory_snapshots: List[MetricSnapshot] = []
        self.current_gpu_snapshots: List[MetricSnapshot] = []
        self.all_syntheses: List[SynthesisMetrics] = []
        
        # Per-second monitoring
        self.monitoring_active = False
        self.monitor_interval_s = 0.1  # Sample every 100ms
        
        self._init_loggers()
        self._save_hardware_specs()
    
    def _init_loggers(self):
        """Initialize CSV loggers for continuous data export"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Synthesis summary log
        self.synthesis_log_path = self.output_dir / f"synthesis_{self.profile.cpu_tier}_{timestamp}.csv"
        
        # Real-time metrics log
        self.realtime_log_path = self.output_dir / f"realtime_{self.profile.cpu_tier}_{timestamp}.csv"
        
        logger.info(f"ðŸ“Š Monitoring logs:")
        logger.info(f"   Synthesis: {self.synthesis_log_path}")
        logger.info(f"   Real-time: {self.realtime_log_path}")
    
    def _save_hardware_specs(self):
        """Save hardware specifications for analysis"""
        specs = {
            "hardware_tier": self.profile.cpu_tier,
            "device_type": self.profile.device_type,
            "cpu_model": self.profile.cpu_model,
            "cores_physical": self.profile.cores_physical,
            "cores_logical": self.profile.cores_logical,
            "memory_gb": self.profile.memory_gb,
            "gpu_name": self.profile.gpu_name,
            "gpu_memory_gb": self.profile.gpu_memory_gb,
            "system": self.profile.system,
            "machine": self.profile.machine,
            "thermal_capable": self.profile.thermal_capable,
            "avx512_vnni": self.profile.avx512_vnni,
        }
        
        specs_file = self.output_dir / f"hardware_specs_{self.profile.cpu_tier}.json"
        with open(specs_file, 'w') as f:
            json.dump(specs, f, indent=2)
        
        logger.info(f"ðŸ’¾ Hardware specs saved: {specs_file}")
    
    def _write_csv_header(self, filepath: Path, fields: List[str]):
        """Write CSV header"""
        if not filepath.exists():
            with open(filepath, 'w', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=fields)
                writer.writeheader()
    
    def start_synthesis(self, text: str, text_tokens: int, ref_audio_s: float, 
                       request_id: str, config: Any):
        """Start monitoring a synthesis request"""
        self.current_synthesis = SynthesisMetrics(
            request_id=request_id,
            hardware_tier=self.profile.cpu_tier,
            device_type=self.profile.device_type,
            cpu_model=self.profile.cpu_model,
            cpu_cores=self.profile.cores_physical,
            total_memory_gb=self.profile.memory_gb,
            gpu_name=self.profile.gpu_name,
            text_length_chars=len(text),
            text_length_tokens=text_tokens,
            reference_audio_seconds=ref_audio_s,
            start_time=time.time(),
            quantization_used=config.quantization,
            torch_compile_used=config.use_torch_compile,
            onnx_used=config.use_onnx,
            chunk_length=config.chunk_length,
            num_threads=config.num_threads,
        )
        
        self.current_memory_snapshots = []
        self.current_gpu_snapshots = []
        self.monitoring_active = True
        
        logger.info(f"[MONITOR] Starting synthesis: {request_id} ({text_tokens} tokens)")
    
    async def monitor_loop(self):
        """Continuously sample system metrics during synthesis"""
        # Write real-time header if needed
        if not self.realtime_log_path.exists():
            snapshot_fields = list(MetricSnapshot(0, 0, 0, 0).to_dict().keys())
            self._write_csv_header(self.realtime_log_path, snapshot_fields)
        
        while self.monitoring_active and self.current_synthesis:
            snapshot = self._take_snapshot()
            self.current_memory_snapshots.append(snapshot)
            
            if snapshot.gpu_memory_mb > 0 or snapshot.temperature_c > 0:
                self.current_gpu_snapshots.append(snapshot)
            
            # Log real-time data
            self._log_realtime_snapshot(snapshot)
            
            await asyncio.sleep(self.monitor_interval_s)
    
    def _take_snapshot(self) -> MetricSnapshot:
        """Capture current system state"""
        # CPU & Memory
        cpu_percent = psutil.cpu_percent(interval=0.01)
        memory = psutil.virtual_memory()
        
        # GPU (if available)
        gpu_memory_mb = 0.0
        gpu_percent = 0.0
        if torch.cuda.is_available():
            try:
                gpu_memory_mb = torch.cuda.memory_allocated() / (1024**2)
                total_memory = torch.cuda.get_device_properties(0).total_memory / (1024**2)
                gpu_percent = (gpu_memory_mb / total_memory) * 100 if total_memory > 0 else 0
            except:
                pass
        elif self.profile.device_type == "mps":
            # Apple Silicon - estimate from system memory
            gpu_memory_mb = memory.used / (1024**2) * 0.6
        
        # Temperature
        temp = self._get_temperature() if self.profile.thermal_capable else 0.0
        
        return MetricSnapshot(
            timestamp=time.time(),
            cpu_percent=cpu_percent,
            memory_mb=memory.used / (1024**2),
            memory_percent=memory.percent,
            gpu_memory_mb=gpu_memory_mb,
            gpu_percent=gpu_percent,
            temperature_c=temp,
        )
    
    def _get_temperature(self) -> float:
        """Get CPU temperature (platform-specific)"""
        try:
            if self.profile.system == "Darwin":  # macOS
                import subprocess
                result = subprocess.run(
                    ['powermetrics', '--n', '1', '-i', '100'],
                    capture_output=True, text=True, timeout=1
                )
                for line in result.stdout.split('\n'):
                    if 'CPU die temperature' in line:
                        try:
                            return float(line.split()[-1].rstrip('Â°C'))
                        except:
                            pass
            elif self.profile.system == "Linux":
                # Try reading thermal zones
                thermal_zones = Path('/sys/class/thermal').glob('thermal_zone*/temp')
                for zone in thermal_zones:
                    try:
                        temp = int(zone.read_text()) / 1000.0
                        if 30 < temp < 120:  # Sanity check
                            return temp
                    except:
                        pass
        except:
            pass
        return 0.0
    
    def _log_realtime_snapshot(self, snapshot: MetricSnapshot):
        """Append real-time snapshot to CSV"""
        with open(self.realtime_log_path, 'a', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=snapshot.to_dict().keys())
            writer.writerow(snapshot.to_dict())
    
    def end_synthesis(self, success: bool = True, error: str = ""):
        """Finalize synthesis metrics"""
        if not self.current_synthesis:
            return
        
        self.current_synthesis.end_time = time.time()
        self.current_synthesis.total_duration_s = (
            self.current_synthesis.end_time - self.current_synthesis.start_time
        )
        self.current_synthesis.success = success
        self.current_synthesis.error_message = error
        
        # Finalize with snapshots
        self.current_synthesis.finalize(
            self.current_memory_snapshots,
            self.current_gpu_snapshots
        )
        
        self.all_syntheses.append(self.current_synthesis)
        
        # Write to CSV
        self._save_synthesis_metrics(self.current_synthesis)
        
        self.monitoring_active = False
        
        logger.info(
            f"[MONITOR] Synthesis complete: {self.current_synthesis.request_id}\n"
            f"  Duration: {self.current_synthesis.total_duration_s:.2f}s\n"
            f"  Peak Memory: {self.current_synthesis.peak_memory_mb:.0f}MB\n"
            f"  RTF: {self.current_synthesis.rtf:.2f}x\n"
            f"  Tokens/sec: {self.current_synthesis.tokens_per_second:.2f}"
        )
    
    def _save_synthesis_metrics(self, metrics: SynthesisMetrics):
        """Save synthesis metrics to CSV"""
        data = asdict(metrics)
        
        # Write header if file doesn't exist
        if not self.synthesis_log_path.exists():
            self._write_csv_header(self.synthesis_log_path, list(data.keys()))
        
        with open(self.synthesis_log_path, 'a', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=data.keys())
            writer.writerow(data)
    
    def export_analysis(self) -> dict:
        """Export comparative analysis across all runs"""
        if not self.all_syntheses:
            return {}
        
        successful = [s for s in self.all_syntheses if s.success]
        
        analysis = {
            "hardware_tier": self.profile.cpu_tier,
            "device_type": self.profile.device_type,
            "cpu_model": self.profile.cpu_model,
            "total_runs": len(self.all_syntheses),
            "successful_runs": len(successful),
            "timestamp": datetime.now().isoformat(),
            
            "memory": {
                "avg_peak_mb": sum(s.peak_memory_mb for s in successful) / len(successful) if successful else 0,
                "max_peak_mb": max((s.peak_memory_mb for s in successful), default=0),
                "min_peak_mb": min((s.peak_memory_mb for s in successful), default=0),
                "std_dev_mb": self._std_dev([s.peak_memory_mb for s in successful]),
            },
            
            "performance": {
                "avg_rtf": sum(s.rtf for s in successful) / len(successful) if successful else 0,
                "avg_tokens_per_sec": sum(s.tokens_per_second for s in successful) / len(successful) if successful else 0,
                "avg_duration_s": sum(s.total_duration_s for s in successful) / len(successful) if successful else 0,
            },
            
            "success_rate": len(successful) / len(self.all_syntheses) if self.all_syntheses else 0,
            
            "thermal": {
                "max_temperature_c": max((s.peak_temperature_c for s in successful), default=0),
                "throttle_events": sum(1 for s in successful if s.throttle_detected),
            },
            
            "configuration": {
                "quantization": successful[0].quantization_used if successful else "",
                "torch_compile": successful[0].torch_compile_used if successful else False,
                "onnx": successful[0].onnx_used if successful else False,
            }
        }
        
        # Save analysis JSON
        analysis_path = self.output_dir / f"analysis_{self.profile.cpu_tier}.json"
        with open(analysis_path, 'w') as f:
            json.dump(analysis, f, indent=2)
        
        logger.info(f"ðŸ“Š Analysis exported: {analysis_path}")
        return analysis
    
    def _std_dev(self, values: List[float]) -> float:
        """Calculate standard deviation"""
        if not values:
            return 0.0
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        return variance ** 0.5
